{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af406d4-1dd0-4905-bb6a-77bdb9f98429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ./work\n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c09db7-b59f-40f3-8c4d-da124c7037f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../catalog_common.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf11553-0fb6-433c-bee9-5521e41a32bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.insert(0,'c:/MyDocs/OpenFF/src/openFF-catalog/')\n",
    "# import catalog_common as cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79085df4-fdd8-4af2-9fbb-0414a407d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preamble to analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import gca, mpl\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker\n",
    "from IPython.display import Markdown as md\n",
    "from IPython.display import HTML, display\n",
    "from time import sleep\n",
    "\n",
    "from itables import init_notebook_mode\n",
    "init_notebook_mode(all_interactive=True)\n",
    "from itables import show as iShow\n",
    "import itables.options as opt\n",
    "opt.order = []  # no sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68199e2-8615-4b62-ae24-56d2bf5602a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldf = pd.read_csv('state.csv',low_memory=False)\n",
    "alldf.date = pd.to_datetime(alldf.date)\n",
    "statename = alldf.bgStateName.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20436324-3169-4ff4-8f7f-df0d28f4a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_header(statename.title(), subtitle='Open-FF State Summary',incl_links=True,\n",
    "          link_up_level=True)\n",
    "set_page_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5cf5c-9ee6-4cee-bbec-830a875e1307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xlate_val(n):\n",
    "    if n==0:\n",
    "        return ''\n",
    "    if n<1000:\n",
    "        return round_sig(n,1)\n",
    "    x = round_sig(n,1)\n",
    "    return x[0]+ 'k'\n",
    "\n",
    "def make_annot(gb):\n",
    "    annot = gb.copy()\n",
    "    annot.UploadKey = annot.UploadKey.map(lambda x: xlate_val(x))\n",
    "    #print(annot)\n",
    "    piv = annot.pivot(index='County',columns='year',values='UploadKey')\n",
    "    piv.fillna('',inplace=True)\n",
    "    #print(piv)\n",
    "    return piv\n",
    "    \n",
    "def CountyMap(df):\n",
    "    start_loc = get_state_center(statename)\n",
    "    #print(statename,start_loc)\n",
    "    cond = (df.loc_within_state=='YES')&(df.loc_within_county=='YES')\n",
    "    if cond.sum()==0:  # no valid fracks for this state\n",
    "        display(md('## No mappable fracks for this state!'))\n",
    "        display(md(f'Any data in this state set may be labeled incorrectly as {statename}'))\n",
    "        return\n",
    "    gb = df[cond].groupby(['bgStateName','bgCountyName',\n",
    "                                                   'UploadKey'],as_index=False)['bgCAS'].count()\n",
    "    gb = gb.groupby(['bgStateName','bgCountyName'],as_index=False)['UploadKey'].count().rename({'bgStateName':'StateName',\n",
    "                                                                                                'bgCountyName':'CountyName',\n",
    "                                                                                                'UploadKey':'value'},\n",
    "                                                                                                axis=1)\n",
    "    zoom = 6\n",
    "    if statename in ['texas','california']:\n",
    "        zoom = 5\n",
    "    if statename in ['alaska']:\n",
    "        zoom = 4\n",
    "        \n",
    "    create_county_choropleth(gb,plotlog=True,custom_scale= [0,1,2,3,4,5],\n",
    "                             start_loc=start_loc, # center of state's data\n",
    "                             legend_name='Number of FracFocus disclosures',\n",
    "                             start_zoom=zoom,fields=['StateName','CountyName','orig_value'],\n",
    "                             aliases=['State: ','County: ','Number Fracking disclosures: '])\n",
    "\n",
    "def CountyCntTable(df):\n",
    "    # first, make the general searchable table\n",
    "    gb = df.groupby(['bgCountyName','UploadKey'],as_index=False)['date'].first()\n",
    "    gb['year'] = gb.date.dt.year.astype('str')\n",
    "    gb1 = gb.groupby(['bgCountyName'],as_index=False)['UploadKey'].count().rename({'UploadKey':'disclosure_count'},\n",
    "                                                                                  axis=1)\n",
    "    gb2 = gb1.copy()\n",
    "    gbop = df.groupby('bgCountyName')['bgOperatorName'].agg(lambda x:x.value_counts().index[0:4]).reset_index()\n",
    "    gbop.bgOperatorName = gbop.bgOperatorName.map(lambda x: xlate_to_str(x,'; ',sort=False))\n",
    "    gbop = gbop.rename({'bgOperatorName':'Top Operators'},axis=1)\n",
    "    gb2 = pd.merge(gb2,gbop,on='bgCountyName',how='left')\n",
    "\n",
    "    gbprop = df[df.bgCAS=='proprietary'].groupby('bgCountyName',as_index=False)['bgCAS'].count()\n",
    "#     gbprop.bgCAS.fillna(0,inplace=True)\n",
    "    gbprop = gbprop.rename({'bgCAS':'Trade Secret records'},axis=1)\n",
    "    gb2 = pd.merge(gb2,gbprop,on='bgCountyName',how='left')\n",
    "    gb2['Trade Secret records'].fillna(0,inplace=True)\n",
    "    \n",
    "    gbtbwv = df.groupby(['bgCountyName','UploadKey'],as_index=False)['TotalBaseWaterVolume'].first()\n",
    "    gbtbwv = gbtbwv.groupby('bgCountyName',as_index=False)['TotalBaseWaterVolume'].sum().rename({'TotalBaseWaterVolume':'tot_gallons_water'},\n",
    "                                                                                                axis=1)\n",
    "    gbtbwv.tot_gallons_water = gbtbwv.tot_gallons_water.map(lambda x: round_sig(x,3))\n",
    "    gb2 = pd.merge(gb2,gbtbwv,on='bgCountyName',how='left')\n",
    "\n",
    "    #print(gb2.head())\n",
    "    gb2['County'] = '<center><h4>'+gb2.bgCountyName.str.title().map(lambda x: getCountyLink(x,statename,x))+'</h4></center>'\n",
    "    gb2 = gb2.drop('bgCountyName',axis=1)\n",
    "    iShow(gb2.sort_values('disclosure_count',ascending=False)[['County','disclosure_count',\n",
    "                                                               'Trade Secret records','tot_gallons_water',\n",
    "                                                               'Top Operators']].reset_index(drop=True),\n",
    "         classes=\"display compact cell-border\")\n",
    "        \n",
    "#     # Now make the heatmap\n",
    "#     gb3 = gb.groupby(['bgCountyName','year'],as_index=False)['UploadKey'].count()\n",
    "#     gb3 = gb3.rename({'bgCountyName':'County'},axis=1)\n",
    "#     gb3 = pd.merge(gb3,gb1,left_on='County',right_on='bgCountyName',how='left')\n",
    "#     gb3.County = gb3.County.str.title()\n",
    "\n",
    "#     gb_annot = make_annot(gb3)\n",
    "#     #print(gb_annot)\n",
    "#     gb3.UploadKey = gb3.UploadKey/gb3.disclosure_count *100\n",
    "#     piv = gb3.pivot(index='County',columns='year',values='UploadKey')\n",
    "#     #piv = piv.reset_index()\n",
    "#     #piv['County'] = '<center><h3>'+piv.CountyName.str.title().map(lambda x: getCountyLink(x,statename,x))+'</h3></center>'\n",
    "#     #piv = piv.drop('CountyName',axis=1)\n",
    "#     piv.fillna(0,inplace=True)\n",
    "\n",
    "    \n",
    "#     fig = plt.figure(figsize=(len(piv.columns)*.75,len(piv)/3+3))\n",
    "#     ax = sns.heatmap(piv,cmap=\"Reds\",annot=gb_annot,fmt='')\n",
    "#     plt.ylabel(f'Counties',fontsize=14);\n",
    "#     plt.xlabel(f'Year',fontsize=14);\n",
    "#     plt.title(f\"Percent Distribution of county's disclosures by year\",fontsize=16)\n",
    "#     #plt.title(\"Annotations are the number of disclosures (rounded)\",fontsize=12)\n",
    "#     ax.set_xticklabels(ax.get_xticklabels(),rotation = 45)\n",
    "#     ax.set_yticklabels(ax.get_yticklabels(),rotation = 0,fontsize=14);\n",
    "#     ax.xaxis.set_ticks_position('top')\n",
    "#     plt.show()\n",
    "#     display(md(\"     Annotations are the number of disclosures that year (rounded)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910bdd39-6067-48f9-8374-93ad27b197c4",
   "metadata": {},
   "source": [
    "# Where are the fracking locations in this state?\n",
    "This is not an exhaustive set of wells in these counties; it is only those wells for which the operating company submits a chemical disclosure to FracFocus.  In addition, this map omits disclosures for which location information is conflicting, such as the Latitude/Longitude values are outside of the reported county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3860db3-6c4d-4dea-9e64-38efc5776d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "CountyMap(alldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ec1a1-a77f-44aa-b6a5-12ecae9409de",
   "metadata": {},
   "source": [
    "---\n",
    "## County-based details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d9482-8289-4bc4-9298-09289e4c1ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CountyCntTable(alldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ecbf70-cd17-42ba-a016-788864b9ac1d",
   "metadata": {},
   "source": [
    "---\n",
    "## Who are the Operators in this state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1991f1-805c-4a31-99e2-8146fbe43652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_water(row):\n",
    "    s = str(round_sig(row.TotalBaseWaterVolume,3))\n",
    "    s += '<br>'\n",
    "    s += str(round_sig(row.TBWV90,3))\n",
    "    return s\n",
    "\n",
    "alldf['year'] = alldf.date.dt.year.astype(str)\n",
    "gbOp = alldf.groupby(['UploadKey','bgCountyName','bgOperatorName','year'],as_index=False)['TotalBaseWaterVolume'].first()\n",
    "gbOp.bgCountyName = gbOp.bgCountyName.str.title()\n",
    "\n",
    "gbOp1 = gbOp.groupby('bgOperatorName',as_index=False)['UploadKey'].count().rename({'UploadKey':'num_fracks'},axis=1)\n",
    "\n",
    "gbOp2 = gbOp.groupby(['bgOperatorName','year'],as_index=False)['UploadKey'].count()\n",
    "gbOp2['year_cnt'] = gbOp2.year + '(' + gbOp2.UploadKey.astype(str) + ')'\n",
    "\n",
    "gbOpY = gbOp2.groupby('bgOperatorName')['year_cnt'].apply(set).reset_index()\n",
    "gbOpY['years'] = gbOpY.year_cnt.map(lambda x: xlate_to_str(x,sep='<br>'))\n",
    "\n",
    "gbOp3 = gbOp.groupby(['bgOperatorName','bgCountyName'],as_index=False)['UploadKey'].count()\n",
    "gbOp3['counties_cnt'] = gbOp3.bgCountyName + '(' + gbOp3.UploadKey.astype(str) + ')'\n",
    "\n",
    "gbOp4 = gbOp3.groupby('bgOperatorName')['counties_cnt'].apply(set).reset_index()\n",
    "gbOp4['counties'] = gbOp4.counties_cnt.map(lambda x: xlate_to_str(x,sep='<br>'))\n",
    "\n",
    "# gbOp5 = df.groupby('bgOperatorName')['OperatorName'].agg(lambda x: x.value_counts().index[0])\n",
    "gbOp5 = alldf.groupby('bgOperatorName')['OperatorName'].apply(set).reset_index()\n",
    "gbOp5['names'] = gbOp5.OperatorName.map(lambda x: xlate_to_str(x,sep='<br>'))\n",
    "# gbOp5.names = gbOp5.names + '<br>[' + gbOp5.bgOperatorName + ']'\n",
    "\n",
    "gbOp6 = gbOp.groupby('bgOperatorName',as_index=False)['TotalBaseWaterVolume'].median()\n",
    "gbOp6.rename({'TotalBaseWaterVolume':'Water,\\nmedian (gal)'},axis=1,inplace=True)\n",
    "# gbOp7 = gbOp.groupby('bgOperatorName',as_index=False)['TotalBaseWaterVolume'].agg(lambda x: np.percentile(x,90))\n",
    "gbOp7 = gbOp.groupby('bgOperatorName',as_index=False)['TotalBaseWaterVolume'].max()\n",
    "gbOp7.rename({'TotalBaseWaterVolume':'Water,\\nmax (gal)'},axis=1,inplace=True)\n",
    "mg = pd.merge(gbOp6,gbOp7,on='bgOperatorName')\n",
    "# mg.fillna(0,inplace=True)\n",
    "# mg['TBWV'] = mg.apply(lambda x: make_water(x),axis=1)\n",
    "mg = pd.merge(mg,gbOp1,on='bgOperatorName')\n",
    "mg = pd.merge(mg,gbOpY,on='bgOperatorName')\n",
    "mg = pd.merge(mg,gbOp4[['bgOperatorName','counties']],on='bgOperatorName')\n",
    "mg = pd.merge(mg,gbOp5,on='bgOperatorName').sort_values('num_fracks',ascending=False)\n",
    "\n",
    "mg['link'] = mg.bgOperatorName.map(lambda x: getOpLink(x,x,up_level=True))\n",
    "mg.names = mg.names + '<br>[' + mg.link + ']'\n",
    "\n",
    "iShow(mg[['names','num_fracks','years','counties','Water,\\nmedian (gal)','Water,\\nmax (gal)']].reset_index(drop=True),\n",
    "      maxBytes=0,columnDefs=[{\"width\": \"150px\", \"targets\": 0}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c77391-8278-4afe-985f-312197ce47df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import AnchoredText\n",
    "\n",
    "\n",
    "def proprietary_plot(df,plot_title='TEST',minyr=2011,maxyr=2021):\n",
    "    df = df.copy()\n",
    "    df['year'] = df.date.dt.year\n",
    "    df = df[df.year<=maxyr]\n",
    "    df = df[df.year>=minyr]\n",
    "    prop = df.bgCAS=='proprietary'\n",
    "    gb = df[prop].groupby('UploadKey',as_index=False)['bgCAS'].count().rename({'bgCAS':'numprop'},axis=1)\n",
    "    gb1 = df[df.is_valid_cas].groupby('UploadKey',as_index=False)['bgCAS'].count().rename({'bgCAS':'numvalid'},axis=1)\n",
    "    gb2 = df.groupby('UploadKey',as_index=False)['date'].first()\n",
    "    mg = pd.merge(gb2,gb,on='UploadKey',how='left')\n",
    "    mg = pd.merge(mg,gb1,on='UploadKey',how='left')\n",
    "    mg.fillna(0,inplace=True) # there will be disclosures with 0 proprietary; need to fill\n",
    "    mg['percProp'] = (mg.numprop / mg.numvalid) * 100\n",
    "\n",
    "    mg['propCut'] = pd.cut(mg.percProp,right=False,bins=[0,0.0001,10,25,50,101],\n",
    "                          labels=['no proprietary claims','up to 10% proprietary claims',\n",
    "                                  'between 10 and 25% proprietary claims',\n",
    "                                  'between 25 and 50% proprietary claims',\n",
    "                                  'greater than 50% proprietary claims'])\n",
    "    mg['year'] = mg.date.dt.year\n",
    "    out = mg.drop(['date','UploadKey'],axis=1)\n",
    "    t = out[out.numvalid>0].groupby(['year','propCut'],as_index=False)['numvalid'].count()\n",
    "    sums = t.groupby('year',as_index=False)['numvalid'].sum().rename({'numvalid':'tot'},axis=1)\n",
    "    t = pd.merge(t,sums,on='year',how='left')\n",
    "    t['PercentProp'] = t.numvalid/t.tot *100\n",
    "\n",
    "    piv = t.pivot(index='year', columns='propCut', values='PercentProp')\n",
    "\n",
    "    ax = piv.plot.area(figsize=(12,7),ylim=(0,100),xlim=(minyr,maxyr),colormap='Reds')\n",
    "    ax.set_title(f'Percentage of valid records that are Trade Secret claims at the disclosure level', fontsize=16)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles[::-1], labels[::-1], title='Disclosure Proprietary\\nPercentage class\\n',\n",
    "              loc='upper left',bbox_to_anchor=(1, 1))\n",
    "    ax.set_ylabel('Percentage of disclosures', fontsize=16)\n",
    "    ax.set_xlabel('Year', fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.suptitle(f'{plot_title}',fontsize=24)\n",
    "\n",
    "    gb = df.groupby(['year','UploadKey'],as_index=False)['bgCAS'].count()\n",
    "    gb = gb.groupby('year',as_index=False)['UploadKey'].count()#.rename({'UploadKey':'number of disclosures'},axis=1)\n",
    "    s = 'Number of disclosures by year:\\n\\n'\n",
    "    for i,row in gb.iterrows():\n",
    "        s+= f'   {row.year}: {row.UploadKey:7,} \\n'\n",
    "    at2 = AnchoredText(s,\n",
    "                       loc='lower left', prop=dict(size=10), frameon=False,\n",
    "                       bbox_to_anchor=(1., 0.),\n",
    "                       bbox_transform=ax.transAxes\n",
    "                       )\n",
    "    at2.patch.set_boxstyle(\"square,pad=0.\")\n",
    "    ax.add_artist(at2)\n",
    "\n",
    "    \n",
    "# test = 'pennsylvania'\n",
    "# variable = 'bgStateName'\n",
    "testtitle = statename.title() +': Trade Secret frequency'\n",
    "if len(alldf.UploadKey.unique())>1000:\n",
    "    # small-number states look silly with this plot\n",
    "    proprietary_plot(alldf,testtitle,minyr=2011,maxyr=alldf.date.dt.year.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b668e85e-b23b-40dd-910f-2586e172eb63",
   "metadata": {},
   "source": [
    "## School districts\n",
    "|field| Description |\n",
    "| :--: | -- |\n",
    "|**NAME**| School District name |\n",
    "|**num_FF_wells** | The number of wells within the district that have reported data in FracFocus. This covers the period from 2011 to the recent. |\n",
    "|**num_all_wells** |  The number of all wells within the district that are recorded by the state-based data, and included non-fracked wells and may go back to the beginning of state-held record keeping - may decades.|\n",
    "|**GEOID**| The national code used to identify this school district. | \n",
    "\n",
    "*Note that many districts will have wells, but no FracFocus wells.  Many will be older and non-fracked; others may not be recorded in FracFocus even though they are fracked.  Furthermore, we don't have state data for all US states yet; we have focused on those that are heavily represented in FracFocus.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d920a-679d-45cb-8ee0-971fb783e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "wells_in_dist_fn = 'FFwells_in_school_districts.csv'\n",
    "distFF = pd.read_csv(wells_in_dist_fn)\n",
    "distFF = distFF[distFF.bgStateName==statename]\n",
    "distFF.num_FF_wells.fillna(0,inplace=True)\n",
    "iShow(distFF[['NAME','GEOID','num_FF_wells','num_all_wells']].reset_index(drop=True),\n",
    "     classes=\"display compact cell-border\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
